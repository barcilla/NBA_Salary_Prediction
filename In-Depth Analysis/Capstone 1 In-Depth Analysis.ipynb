{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/nba_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OneHotEncode Positions and drop columns\n",
    "df = pd.concat([df, pd.get_dummies(df['Pos'])],axis=1)\n",
    "\n",
    "#Group my percentage ranges.\n",
    "group = pd.cut(df['%_of_cap'],[0,0.1,0.15,0.2,0.25,df['%_of_cap'].max()], \n",
    "               labels=['0-10%','10%-15%','15%-20%','20%-25%','25%<='])\n",
    "df['group']=group\n",
    "\n",
    "df.drop(['Pos', '%_of_cap'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['Age', 'G', 'MP', 'PER', 'TS%', '3PAr', 'FTr', 'TRB%', 'AST%', 'STL%',\n",
    "                 'BLK%', 'TOV%', 'USG%', 'WS', 'BPM', 'C', 'PF', 'PG', 'SF', 'SG']\n",
    "\n",
    "X = np.array(df.iloc[:,0:20])\n",
    "y = np.array(df.group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>G</th>\n",
       "      <th>MP</th>\n",
       "      <th>PER</th>\n",
       "      <th>TS%</th>\n",
       "      <th>3PAr</th>\n",
       "      <th>FTr</th>\n",
       "      <th>TRB%</th>\n",
       "      <th>AST%</th>\n",
       "      <th>STL%</th>\n",
       "      <th>...</th>\n",
       "      <th>TOV%</th>\n",
       "      <th>USG%</th>\n",
       "      <th>WS</th>\n",
       "      <th>BPM</th>\n",
       "      <th>C</th>\n",
       "      <th>PF</th>\n",
       "      <th>PG</th>\n",
       "      <th>SF</th>\n",
       "      <th>SG</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26</td>\n",
       "      <td>57</td>\n",
       "      <td>2029</td>\n",
       "      <td>18.6</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.164</td>\n",
       "      <td>3.9</td>\n",
       "      <td>34.7</td>\n",
       "      <td>1.6</td>\n",
       "      <td>...</td>\n",
       "      <td>10.1</td>\n",
       "      <td>25.1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10%-15%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31</td>\n",
       "      <td>53</td>\n",
       "      <td>516</td>\n",
       "      <td>9.6</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.133</td>\n",
       "      <td>10.6</td>\n",
       "      <td>9.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>13.4</td>\n",
       "      <td>17.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-5.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0-10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>60</td>\n",
       "      <td>560</td>\n",
       "      <td>8.7</td>\n",
       "      <td>0.506</td>\n",
       "      <td>0.426</td>\n",
       "      <td>0.161</td>\n",
       "      <td>4.2</td>\n",
       "      <td>31.6</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>29.1</td>\n",
       "      <td>18.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-4.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0-10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>41</td>\n",
       "      <td>362</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.447</td>\n",
       "      <td>0.314</td>\n",
       "      <td>0.343</td>\n",
       "      <td>4.1</td>\n",
       "      <td>20.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-6.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0-10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>73</td>\n",
       "      <td>1614</td>\n",
       "      <td>11.8</td>\n",
       "      <td>0.518</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.289</td>\n",
       "      <td>10.8</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>...</td>\n",
       "      <td>11.9</td>\n",
       "      <td>13.7</td>\n",
       "      <td>1.7</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0-10%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age   G    MP   PER    TS%   3PAr    FTr  TRB%  AST%  STL%   ...     TOV%  \\\n",
       "0   26  57  2029  18.6  0.535  0.324  0.164   3.9  34.7   1.6   ...     10.1   \n",
       "1   31  53   516   9.6  0.489  0.055  0.133  10.6   9.2   0.9   ...     13.4   \n",
       "2   22  60   560   8.7  0.506  0.426  0.161   4.2  31.6   2.5   ...     29.1   \n",
       "3   23  41   362   7.8  0.447  0.314  0.343   4.1  20.8   3.0   ...     22.0   \n",
       "4   23  73  1614  11.8  0.518  0.008  0.289  10.8   6.5   1.8   ...     11.9   \n",
       "\n",
       "   USG%   WS  BPM  C  PF  PG  SF  SG    group  \n",
       "0  25.1  5.5  1.1  0   0   1   0   0  10%-15%  \n",
       "1  17.7  0.2 -5.2  0   0   0   1   0    0-10%  \n",
       "2  18.8  0.2 -4.7  0   0   1   0   0    0-10%  \n",
       "3  19.0 -0.3 -6.1  0   0   0   0   1    0-10%  \n",
       "4  13.7  1.7 -1.8  1   0   0   0   0    0-10%  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, cross_validate, cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#Create dictionary of classifiers to try\n",
    "classifiers = {'DecisionTree': DecisionTreeClassifier(random_state=34),  \n",
    "               'RandomForest': RandomForestClassifier(random_state=34), \n",
    "               'SVC': SVC(random_state=34),   \n",
    "               'AdaBoost': AdaBoostClassifier(random_state=34),\n",
    "               'XGBoost': XGBClassifier(random_state=34)}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 34)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandon.arcilla/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/brandon.arcilla/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/brandon.arcilla/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/brandon.arcilla/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/brandon.arcilla/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/brandon.arcilla/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/brandon.arcilla/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/brandon.arcilla/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/brandon.arcilla/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/brandon.arcilla/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/brandon.arcilla/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/brandon.arcilla/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/brandon.arcilla/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/brandon.arcilla/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/brandon.arcilla/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "model_eval = pd.DataFrame({})\n",
    "for key, classifier in classifiers.items():\n",
    "    pipe = Pipeline(steps=[('minmax', MinMaxScaler()),\n",
    "                           ('classifier', classifier)])\n",
    "    kfold = KFold(n_splits=5, random_state=34)\n",
    "    scores = cross_validate(pipe, X_train, y_train, cv=kfold) #Use cross_val_score to get the mean of each fold and standard deviation\n",
    "    model_eval = model_eval.append({'classifier':key,    \n",
    "                                    'mean_fit_time':scores['fit_time'].mean(),\n",
    "                                    'mean_score_time':scores['score_time'].mean(),                       \n",
    "                                    'mean_test_score':scores['test_score'].mean(),\n",
    "                                    'std_test_score':scores['test_score'].std(),\n",
    "                                    'mean_train_score':scores['train_score'].mean(),\n",
    "                                    'std_train_score':scores['train_score'].mean()}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.093074</td>\n",
       "      <td>0.666398</td>\n",
       "      <td>0.007840</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.164730</td>\n",
       "      <td>0.745540</td>\n",
       "      <td>0.009935</td>\n",
       "      <td>0.983501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC</td>\n",
       "      <td>1.325872</td>\n",
       "      <td>0.730651</td>\n",
       "      <td>0.011307</td>\n",
       "      <td>0.731388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.869530</td>\n",
       "      <td>0.747150</td>\n",
       "      <td>0.009784</td>\n",
       "      <td>0.758417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>5.224224</td>\n",
       "      <td>0.758417</td>\n",
       "      <td>0.011314</td>\n",
       "      <td>0.793427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     classifier  mean_fit_time  mean_test_score  std_test_score  \\\n",
       "0  DecisionTree       0.093074         0.666398        0.007840   \n",
       "1  RandomForest       0.164730         0.745540        0.009935   \n",
       "2           SVC       1.325872         0.730651        0.011307   \n",
       "3      AdaBoost       0.869530         0.747150        0.009784   \n",
       "4       XGBoost       5.224224         0.758417        0.011314   \n",
       "\n",
       "   mean_train_score  \n",
       "0          1.000000  \n",
       "1          0.983501  \n",
       "2          0.731388  \n",
       "3          0.758417  \n",
       "4          0.793427  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_eval[['classifier', 'mean_fit_time', 'mean_test_score', \n",
    "            'std_test_score', 'mean_train_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers_opt = {'RandomForest': RandomForestClassifier(random_state=34),             \n",
    "                   'AdaBoost': AdaBoostClassifier(random_state=34)}\n",
    "model_eval2 = pd.DataFrame({})\n",
    "\n",
    "for key, classifier in classifiers_opt.items():\n",
    "    model_def = Pipeline(steps=[('minmax', MinMaxScaler()),                          \n",
    "                                ('classifier', classifier)])\n",
    "    model_def.fit(X_train, y_train)\n",
    "    model_eval2 = model_eval2.append({'classifier':key,    \n",
    "                                    'accuracy_score':model_def.score(X_test, y_test),\n",
    "                                     'cm':confusion_matrix(y_test,model_def.predict(X_test)),\n",
    "                                     'class_report': classification_report(y_test,model_def.predict(X_test),output_dict=True)}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 905,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>accuracy_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.757344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.755332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     classifier  accuracy_score\n",
       "0  RandomForest        0.757344\n",
       "1      AdaBoost        0.755332"
      ]
     },
     "execution_count": 905,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_eval2[['classifier', 'accuracy_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 903,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unpacking Classification Report\n",
    "metrics = pd.DataFrame({})\n",
    "\n",
    "classification_report = model_eval2[['classifier',                                          \n",
    "                                     'class_report']].set_index('classifier').to_dict()\n",
    "\n",
    "for key_1, val_1 in classification_report.items():\n",
    "    for key_2, val_2 in val_1.items():\n",
    "        for key_3, val_3 in val_2.items():\n",
    "            for key_4, val_4 in val_3.items():\n",
    "                metrics = metrics.append({'classifier':key_2,                                  \n",
    "                                          'group':key_3,                                  \n",
    "                                         'metric':key_4, \n",
    "                                         'value':val_4},ignore_index=True)\n",
    "\n",
    "#Create pivot table of classification table\n",
    "classification_table = pd.pivot_table(metrics,                        \n",
    "                                      values='value',                      \n",
    "                                      index=['classifier', 'metric'],                      \n",
    "                                     columns='group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 904,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>0-10%</th>\n",
       "      <th>10%-15%</th>\n",
       "      <th>15%-20%</th>\n",
       "      <th>20%-25%</th>\n",
       "      <th>25%&lt;=</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>micro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classifier</th>\n",
       "      <th>metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">AdaBoost</th>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.893530</td>\n",
       "      <td>0.182278</td>\n",
       "      <td>0.091837</td>\n",
       "      <td>0.105960</td>\n",
       "      <td>0.463576</td>\n",
       "      <td>0.347436</td>\n",
       "      <td>0.755332</td>\n",
       "      <td>0.710217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.833650</td>\n",
       "      <td>0.262774</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.145455</td>\n",
       "      <td>0.426829</td>\n",
       "      <td>0.405742</td>\n",
       "      <td>0.755332</td>\n",
       "      <td>0.692609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.962678</td>\n",
       "      <td>0.139535</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.507246</td>\n",
       "      <td>0.349085</td>\n",
       "      <td>0.755332</td>\n",
       "      <td>0.755332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>1822.000000</td>\n",
       "      <td>258.000000</td>\n",
       "      <td>171.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>2485.000000</td>\n",
       "      <td>2485.000000</td>\n",
       "      <td>2485.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">RandomForest</th>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.890909</td>\n",
       "      <td>0.188586</td>\n",
       "      <td>0.129870</td>\n",
       "      <td>0.165414</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.363845</td>\n",
       "      <td>0.757344</td>\n",
       "      <td>0.712802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.825070</td>\n",
       "      <td>0.262069</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.297297</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.429744</td>\n",
       "      <td>0.757344</td>\n",
       "      <td>0.689398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.968167</td>\n",
       "      <td>0.147287</td>\n",
       "      <td>0.087719</td>\n",
       "      <td>0.114583</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.341812</td>\n",
       "      <td>0.757344</td>\n",
       "      <td>0.757344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>1822.000000</td>\n",
       "      <td>258.000000</td>\n",
       "      <td>171.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>2485.000000</td>\n",
       "      <td>2485.000000</td>\n",
       "      <td>2485.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "group                         0-10%     10%-15%     15%-20%    20%-25%  \\\n",
       "classifier   metric                                                      \n",
       "AdaBoost     f1-score      0.893530    0.182278    0.091837   0.105960   \n",
       "             precision     0.833650    0.262774    0.360000   0.145455   \n",
       "             recall        0.962678    0.139535    0.052632   0.083333   \n",
       "             support    1822.000000  258.000000  171.000000  96.000000   \n",
       "RandomForest f1-score      0.890909    0.188586    0.129870   0.165414   \n",
       "             precision     0.825070    0.262069    0.250000   0.297297   \n",
       "             recall        0.968167    0.147287    0.087719   0.114583   \n",
       "             support    1822.000000  258.000000  171.000000  96.000000   \n",
       "\n",
       "group                        25%<=    macro avg    micro avg  weighted avg  \n",
       "classifier   metric                                                         \n",
       "AdaBoost     f1-score     0.463576     0.347436     0.755332      0.710217  \n",
       "             precision    0.426829     0.405742     0.755332      0.692609  \n",
       "             recall       0.507246     0.349085     0.755332      0.755332  \n",
       "             support    138.000000  2485.000000  2485.000000   2485.000000  \n",
       "RandomForest f1-score     0.444444     0.363845     0.757344      0.712802  \n",
       "             precision    0.514286     0.429744     0.757344      0.689398  \n",
       "             recall       0.391304     0.341812     0.757344      0.757344  \n",
       "             support    138.000000  2485.000000  2485.000000   2485.000000  "
      ]
     },
     "execution_count": 904,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning\n",
    "\n",
    "Will begin with using GridSearch for AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('minmax', MinMaxScaler(copy=True, feature_range=(0, 1))), ('grid', GridSearchCV(cv=KFold(n_splits=5, random_state=34, shuffle=False),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimator...   pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0))])"
      ]
     },
     "execution_count": 887,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid_ada = {'learning_rate':[.001, .01, .1],                                \n",
    "                  'n_estimators':[500, 1000, 2000],                                                   \n",
    "                  'random_state':[34]}\n",
    "\n",
    "kfold = KFold(n_splits=5, random_state=34)\n",
    "grid = GridSearchCV(AdaBoostClassifier(), param_grid = param_grid_ada ,cv=kfold)\n",
    "\n",
    "pipe_ada = Pipeline(steps = [('minmax', MinMaxScaler()),\n",
    "                            ('grid', grid)])\n",
    "pipe_ada.fit(X_train, y_train)\n",
    "\n",
    "#grid = grid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 893,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy:  0.7637826961770624\n",
      "Training Score:  0.7691482226693495\n",
      "Best Parameters:  {'learning_rate': 0.1, 'n_estimators': 1000, 'random_state': 34}\n"
     ]
    }
   ],
   "source": [
    "ada_predict = pipe_ada.predict(X_test)\n",
    "print('Model Accuracy: ', accuracy_score(y_test, ada_predict))\n",
    "print('Training Score: ' , pipe_ada.score(X_train, y_train))\n",
    "print('Best Parameters: ', pipe_ada.steps[1][1].best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1762   33    2   11   14]\n",
      " [ 192   39    8    4   15]\n",
      " [  84   38   11   10   28]\n",
      " [  36   15    9   14   22]\n",
      " [  18   23    6   19   72]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, ada_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 894,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0-10%       0.84      0.97      0.90      1822\n",
      "     10%-15%       0.26      0.15      0.19       258\n",
      "     15%-20%       0.31      0.06      0.11       171\n",
      "     20%-25%       0.24      0.15      0.18        96\n",
      "       25%<=       0.48      0.52      0.50       138\n",
      "\n",
      "   micro avg       0.76      0.76      0.76      2485\n",
      "   macro avg       0.43      0.37      0.38      2485\n",
      "weighted avg       0.70      0.76      0.72      2485\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, ada_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('minmax', MinMaxScaler(copy=True, feature_range=(0, 1))), ('grid', GridSearchCV(cv=KFold(n_splits=5, random_state=34, shuffle=False),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimator...   pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid_ada = {'learning_rate':[.1],                                \n",
    "                  'n_estimators':[1000],                                                   \n",
    "                  'random_state':[34]}\n",
    "\n",
    "kfold = KFold(n_splits=5, random_state=34)\n",
    "grid = GridSearchCV(AdaBoostClassifier(), param_grid = param_grid_ada ,cv=kfold)\n",
    "\n",
    "pipe_ada = Pipeline(steps = [('minmax', MinMaxScaler()),\n",
    "                            ('grid', grid)])\n",
    "pipe_ada.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age = 0.117\n",
      "G = 0.139\n",
      "MP = 0.162\n",
      "PER = 0.039\n",
      "TS% = 0.078\n",
      "3PAr = 0.015\n",
      "FTr = 0.054\n",
      "TRB% = 0.078\n",
      "AST% = 0.038\n",
      "STL% = 0.039\n",
      "BLK% = 0.036\n",
      "TOV% = 0.05\n",
      "USG% = 0.066\n",
      "WS = 0.02\n",
      "BPM = 0.067\n",
      "C = 0.0\n",
      "PF = 0.002\n",
      "PG = 0.0\n",
      "SF = 0.0\n",
      "SG = 0.0\n"
     ]
    }
   ],
   "source": [
    "for feature, importance in zip(feature_names, pipe_ada.steps[1][1].best_estimator_.feature_importances_):\n",
    "    print (feature, '=', importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "features = feature_names\n",
    "importances = pipe_ada.steps[1][1].best_estimator_.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "_ = plt.title('Feature Importances')\n",
    "_ = plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "_ = plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "_ = plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 898,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('minmax', MinMaxScaler(copy=True, feature_range=(0, 1))), ('grid_rf', GridSearchCV(cv=KFold(n_splits=5, random_state=34, shuffle=False),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=...   pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0))])"
      ]
     },
     "execution_count": 898,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid_rf = {'max_features':['auto', 'sqrt', 'log2'],                                  \n",
    "                 'n_estimators':[500, 1000, 2000],  \n",
    "                 'max_depth':[2, 3, 5, 8],\n",
    "                 'random_state':[34]}\n",
    "\n",
    "kfold = KFold(n_splits=5, random_state=34)\n",
    "grid_rf = GridSearchCV(RandomForestClassifier(), param_grid = param_grid_rf ,cv=kfold)\n",
    "\n",
    "pipe_rf = Pipeline(steps = [('minmax', MinMaxScaler()),\n",
    "                            ('grid_rf', grid_rf)])\n",
    "pipe_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy:  0.7625754527162978\n",
      "Training Score:  0.794634473507713\n",
      "Best Parameters:  {'max_depth': 8, 'max_features': 'auto', 'n_estimators': 2000, 'random_state': 34}\n"
     ]
    }
   ],
   "source": [
    "rf_predict = pipe_rf.predict(X_test)\n",
    "\n",
    "print('Model Accuracy: ', accuracy_score(y_test, rf_predict))\n",
    "print('Training Score: ' , pipe_rf.score(X_train, y_train))\n",
    "print('Best Parameters: ', pipe_rf.steps[1][1].best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 859,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1803    6    1    1   11]\n",
      " [ 226   16    5    0   11]\n",
      " [ 126   10    4    1   30]\n",
      " [  63    5    0    0   28]\n",
      " [  50   10    5    1   72]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, rf_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 858,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0-10%       0.79      0.99      0.88      1822\n",
      "     10%-15%       0.34      0.06      0.10       258\n",
      "     15%-20%       0.27      0.02      0.04       171\n",
      "     20%-25%       0.00      0.00      0.00        96\n",
      "       25%<=       0.47      0.52      0.50       138\n",
      "\n",
      "   micro avg       0.76      0.76      0.76      2485\n",
      "   macro avg       0.38      0.32      0.31      2485\n",
      "weighted avg       0.66      0.76      0.69      2485\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, rf_predict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
